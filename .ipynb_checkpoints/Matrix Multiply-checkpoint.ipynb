{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import torch\n",
    "from torch import tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1=torch.rand([10,56,85])\n",
    "m2=torch.rand([10,85,56])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89.7 µs ± 1.51 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 56, 56])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%timeit torch.matmul(m1,m2)\n",
    "torch.matmul(m1,m2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_matmul(m1,m2):\n",
    "    out=torch.zeros([len(m1),len(m1[0]),len(m2[0][0])])\n",
    "    for i in range(0,len(m1)):\n",
    "        for ix in range(len(m1[0])):\n",
    "            for iy in range(len(m2[0][0])):\n",
    "                out[i,ix,iy]=(m1[i][ix]*m2[i][:,iy]).sum()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90.6 µs ± 816 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n",
      "1.06 s ± 8.95 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit torch.matmul(m1,m2)\n",
    "%timeit naive_matmul(m1,m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def less_naive_matmul(m1,m2):\n",
    "    out=torch.zeros([len(m1),len(m1[0]),len(m2[0][0])])\n",
    "    for i in range(0,len(m1)):\n",
    "        for ix in range(len(m1[0])):\n",
    "                out[i,ix]=(m1[i][ix][:,None]*m2[i]).sum(dim=0)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96.2 µs ± 3.86 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n",
      "1.06 s ± 3.56 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "26.7 ms ± 30.5 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit torch.matmul(m1,m2)\n",
    "%timeit naive_matmul(m1,m2)\n",
    "%timeit less_naive_matmul(m1,m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lesser_naive_matmul(m1,m2):\n",
    "    out=torch.zeros([len(m1),len(m1[0]),len(m2[0][0])])\n",
    "    for i in range(0,len(m1)):\n",
    "        (m1[i].unsqueeze(-1)*m2[i]).sum(-2)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90.6 µs ± 3.05 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n",
      "1.07 s ± 2.77 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "26.7 ms ± 18.1 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "3.39 ms ± 946 ns per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit torch.matmul(m1,m2)\n",
    "%timeit naive_matmul(m1,m2)\n",
    "%timeit less_naive_matmul(m1,m2)\n",
    "%timeit lesser_naive_matmul(m1,m2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thought is would be a good idea to move all the way down to a fully broadcasted version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_matmul(m1,m2):\n",
    "    return (m1[...,None]*m2[:][:,None]).sum(-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90.8 µs ± 3.11 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n",
      "1.06 s ± 1.05 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "26.6 ms ± 25.7 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "3.38 ms ± 993 ns per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "3.02 ms ± 1.39 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit torch.matmul(m1,m2)\n",
    "%timeit naive_matmul(m1,m2)\n",
    "%timeit less_naive_matmul(m1,m2)\n",
    "%timeit lesser_naive_matmul(m1,m2)\n",
    "%timeit my_matmul(m1,m2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thought changing m1 to shape [10, 54, 1, 85] and [10, 1, 56, 85] to allow for [85]*[56,85] would inprove perf. This was not the case. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alt_matmul(m1,m2):\n",
    "    return (m1[:,:,None]*m2.transpose(1,2)[:,None]).sum(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88.2 µs ± 1.58 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n",
      "1.07 s ± 1.93 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "26.3 ms ± 52.4 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "3.38 ms ± 913 ns per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "3.02 ms ± 4.86 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "3.03 ms ± 3.73 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit torch.matmul(m1,m2)\n",
    "%timeit naive_matmul(m1,m2)\n",
    "%timeit less_naive_matmul(m1,m2)\n",
    "%timeit lesser_naive_matmul(m1,m2)\n",
    "%timeit my_matmul(m1,m2)\n",
    "%timeit alt_matmul(m1,m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89.6 µs ± 275 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n",
      "1.02 s ± 1.03 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "25.4 ms ± 54 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "3.28 ms ± 1.53 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "2.9 ms ± 1.14 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "2.9 ms ± 1.41 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "118 µs ± 417 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit torch.matmul(m1,m2)\n",
    "%timeit naive_matmul(m1,m2)\n",
    "%timeit less_naive_matmul(m1,m2)\n",
    "%timeit lesser_naive_matmul(m1,m2)\n",
    "%timeit my_matmul(m1,m2)\n",
    "%timeit alt_matmul(m1,m2)\n",
    "%timeit torch.einsum('bik,bkj->bij',m1,m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90.1 µs ± 728 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n",
      "1.02 s ± 2.28 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "25.4 ms ± 41.5 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "3.28 ms ± 1.05 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "2.9 ms ± 1.61 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "2.91 ms ± 1.44 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "118 µs ± 191 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n",
      "89.8 µs ± 990 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit torch.matmul(m1,m2)\n",
    "%timeit naive_matmul(m1,m2)\n",
    "%timeit less_naive_matmul(m1,m2)\n",
    "%timeit lesser_naive_matmul(m1,m2)\n",
    "%timeit my_matmul(m1,m2)\n",
    "%timeit alt_matmul(m1,m2)\n",
    "%timeit torch.einsum('bik,bkj->bij',m1,m2)\n",
    "%timeit m1@m2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Playing with Einsums"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Want to get a basic understanding of einsums, as they seem very powerful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "e1=torch.rand([10,7,5])\n",
    "e2=torch.rand([10,5,9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 7, 9])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#matmul\n",
    "torch.einsum('bik,bkj->bij',e1,e2).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 5, 7])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.einsum('bik->bki',e1).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Added deminsion instead of adding up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 7, 9, 5])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.einsum('bik,bkj->bijk',e1,e2).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pointless but interesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 7, 5, 10, 5, 9])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.einsum('abc,def->abcdef',e1,e2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
